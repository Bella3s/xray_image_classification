{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working in Google CoLab Setup\n",
    "\n",
    "This sheet gives a detailed explanation and prep work code needed to run the project properly in Google CoLab.  You will need your Kaggle username as well as your Kaggle API key.  Furthermore, when running the lab itself, you might need to decrease the patience (which will affect the end results) for the more complex models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "\n",
    "This section goes through preparing the Google CoLab environment to receive and download the dataset from Kaggle.  Again, please note you will need to have your Kaggle username and API key on hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(88)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep Google CoLab environment to download data from Kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!touch ~/.kaggle/kaggle.json\n",
    "\n",
    "username = ''  ## Your Kaggle username\n",
    "api_key = ''  ## Your Kaggle API key\n",
    "\n",
    "api_token = {\"username\": username,\n",
    "             \"key\": api_key}\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from Kaggle\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell unzips the downloaded data\n",
    "shutil.unpack_archive('chest-xray-pneumonia.zip', '/content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Data\n",
    "\n",
    "The Original Dataset is already presorted into train/validate/test groups.  However, less than 1% of the data was assigned to the validation folder.  For the purposes of this project, approximately 10% of the images from the train set were transferred to the validation set to get closer to an 80/10/10 split between the train/validate/test groups. \n",
    "\n",
    "The below section goes through the process of investigating the file organization of the downloaded data.  For a better understanding of the project, you can run through this code.  If you already are comfortable with this, feel free to skip to the next section where the images are moved from train to validate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View structure of the raw downloaded data\n",
    "print(os.listdir('./chest_xray'))\n",
    "\n",
    "# View structure of train folder\n",
    "print(os.listdir('./chest_xray/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('./chest_xray/train/NORMAL')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_normal_train = len(os.listdir('./chest_xray/train/NORMAL'))\n",
    "len_pneu_train = len(os.listdir('./chest_xray/train/PNEUMONIA'))\n",
    "len_total_train = len_normal_train + len_pneu_train\n",
    "\n",
    "print(\"There are\", len_normal_train, \"normal xrays in the training set.\")\n",
    "print(\"There are\", len_pneu_train, \"pneumonia xrays in the training set.\")\n",
    "print(\"There are\", len_total_train, \"images total in the training set.\\n\")\n",
    "\n",
    "print('Target Distributon:')\n",
    "print('{}% normal'.format(round(len_normal_train/len_total_train * 100, 2)))\n",
    "print('{}% pneumonia'.format(round(len_pneu_train/len_total_train * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_normal_val = len(os.listdir('./chest_xray/val/NORMAL'))\n",
    "len_pneu_val = len(os.listdir('./chest_xray/val/PNEUMONIA'))\n",
    "len_total_val = len_normal_val + len_pneu_val\n",
    "\n",
    "len_normal_test = len(os.listdir('./chest_xray/test/NORMAL'))\n",
    "len_pneu_test = len(os.listdir('./chest_xray/test/PNEUMONIA'))\n",
    "len_total_test = len_normal_test + len_pneu_test\n",
    "\n",
    "print(\"There are\", len_total_val, \"images total in the validation set.\")\n",
    "print(\"There are\", len_total_test, \"images total in the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_total = len_total_train + len_total_val + len_total_test\n",
    "print('Using {}% of data to train'.format(round(len_total_train / num_images_total *100,2)))\n",
    "print('Using {}% of data to validate'.format(round(len_total_val / num_images_total *100,2)))\n",
    "print('Using {}% of data to test'.format(round(len_total_test / num_images_total *100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Pictures\n",
    "\n",
    "As noted above, less than 1% of all the data was assigned to the validation folder.  For the purposes of this project, an 80/10/10 split was more desirable.  Run the cells below to transfer about 10% of the data from the train folder to the validation folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About how many images to move over -- 10% of total train data.  \n",
    "len_total_train * .1  / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of file names for train normal + train pneumonia\n",
    "\n",
    "normal_train_images = [file for file in os.listdir('./chest_xray/train/NORMAL')]\n",
    "pneu_train_images = [file for file in os.listdir('./chest_xray/train/PNEUMONIA')]\n",
    "\n",
    "# randomly choose indicies for 5% of data (both normal + pneumonia)\n",
    "normal_inds = np.random.choice(range(len_normal_train), size=260, replace=False)\n",
    "pneu_inds = np.random.choice(range(len_pneu_train), size=260, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move chosen images to validation folders\n",
    "\n",
    "for i in normal_inds:\n",
    "    image = normal_train_images[i]\n",
    "    origin = './chest_xray/train/NORMAL/' + image\n",
    "    destination = './chest_xray/val/NORMAL/' + image\n",
    "    shutil.move(origin, destination)\n",
    "    \n",
    "for i in pneu_inds:\n",
    "    image = pneu_train_images[i]\n",
    "    origin = './chest_xray/train/PNEUMONIA/' + image\n",
    "    destination = './chest_xray/val/PNEUMONIA/' + image\n",
    "    shutil.move(origin, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Here\n",
    "\n",
    "Now your Google CoLab environment is set up to run the project!  The full project can be found on [Git Hub](https://github.com/Bella3s/xray_image_classification/blob/main/index.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
