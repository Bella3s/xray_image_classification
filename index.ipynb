{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Ray Image Classification Project\n",
    "\n",
    "Phase 4 Project by Bella Scribner\n",
    "- Flex/\n",
    "- Instructor: Morgan Jones\n",
    "- Bog:\n",
    "- Date of Review:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "# Introduction\n",
    "\n",
    "## The Business Problem\n",
    "\n",
    "\n",
    "### Pneumonia\n",
    "- Who is the business and what is the project about and why?  What is the business looking for?  (what evaluation metrics might be most applicable based on this evaluation?)\n",
    "\n",
    "[WHO](https://www.who.int/news-room/fact-sheets/detail/pneumonia)\n",
    "[UNICEF](https://www.unicef.org/stories/childhood-pneumonia-explained)\n",
    "\n",
    "- \"biggest infectious killer of children worldwide\"\n",
    "- \"more than 725,000 children under age of 5, including around 190,000 newborns, who are particularly vulnerable to infection\"\n",
    "\n",
    "- bacterial, fungal, or viral (different kinds)\n",
    "- infection of the lungs which fill up with liquid (alveoli fill with pus and fluid) --> makes breathing painful and limits oxygen intake\n",
    "\n",
    "- deaths highest in southern Asia + sub-Saharan Africa -- concentrated in the world's poorest countries\n",
    "- areas without strong health care systems health workers often rely on diagnosing pneumonia by counting # of breath per min.  (few doctors, lack of access to chest x-rays + labs)\n",
    "    - MAKES IDEA OF THIS PROJECT HARD --> idea is to expand access to health care, make it easier to diagnose, but this project needs an x-ray which then limits who can benefit from it...\n",
    "\n",
    "- treatment depends on type of --> antibiotics if bacterial (most common), oxygen if available (for all types, but generally only more sever cases)\n",
    "\n",
    "- chest x-rays are used to diagnos pneumonia based on the inflamation of the lungs\n",
    "- [RadiologyInfo.org](https://www.radiologyinfo.org/en/info/pneumonia#:~:text=When%20interpreting%20the%20x%2Dray,(fluid%20surrounding%20the%20lungs).)\n",
    "- look for white spots in the lungs (called infilrates) that id an infection)  also helps determine if have complications related to pneumonia such as abscesses or pleural effusions (fluid surrounding the lungs)\n",
    "\n",
    "### The Business + Project\n",
    "\n",
    "- [UNICEF Venture Fund](https://www.unicef.org/innovation/venturefund/ai-ds-learning-health-cohort)\n",
    "- [UNICEF Neural Labs Africa](https://www.unicefventurefund.org/story/neural-labs-using-ai-accelerate-medical-imaging-diagnosis-respiratory-diseases)\n",
    "- [Neural Labs Africa](https://neurallabs.africa/#)\n",
    "\n",
    "- In April 2022, UNICEF Venture Fund annouced most recent investments, whic included investing in a company called Neural Labs Africa.  Neural Labs Africa is focused on using deep learning and computer vision to identify diseases in real time.  \n",
    "\n",
    "- That is the inspiration for this project!  Want to us AI screening to improve patient care. :D \n",
    "\n",
    "- This project --> create a model that can be used as a pre-screening for patients, giving a prediction on whether or not the patient has pneumonia.  Based on the seriousness of pneumonia in children, will want to evaluate our model with more than just accuracy -- think precision :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Source\n",
    "\n",
    "- Reproducability!  Make sure to include how to download/access. Also note which versions using in this lab of each python library.\n",
    "\n",
    "- Data Downloaded from Kaggle: [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "## The overview\n",
    "- From notes of last review --> keep this more contextual and word driven on the front end.  Can talk about results on the back end but want it mostly connected to the header!  \n",
    "- Don't forget to include target distribution as well as visuals of data in general.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed exploration\n",
    "\n",
    "- image sample\n",
    "- distribution of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(88)\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from keras.models import Sequential\n",
    "#from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chest_xray', 'test', 'train', 'val', '__MACOSX']\n",
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "# structure of downloaded data\n",
    "print(os.listdir('./chest_xray'))\n",
    "\n",
    "# structure of train folder\n",
    "print(os.listdir('./chest_xray/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('./chest_xray/train/NORMAL')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have our data structured such that it is already divided into Train, Validation, and Test segments.  Within those folders the images are stored in two folders based on whether the image is one where pneumonia is present or not.  Let's take a look at the distribution of our target within the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1341 normal xrays in the training set.\n",
      "There are 3875 pneumonia xrays in the training set.\n",
      "There are 5216 images total in the training set.\n",
      "\n",
      "Target Distributon:\n",
      "25.71% normal\n",
      "74.29% pneumonia\n"
     ]
    }
   ],
   "source": [
    "len_normal_train = len(os.listdir('./chest_xray/train/NORMAL'))\n",
    "len_pneu_train = len(os.listdir('./chest_xray/train/PNEUMONIA'))\n",
    "len_total_train = len_normal_train + len_pneu_train\n",
    "\n",
    "print(\"There are\", len_normal_train, \"normal xrays in the training set.\")\n",
    "print(\"There are\", len_pneu_train, \"pneumonia xrays in the training set.\")\n",
    "print(\"There are\", len_total_train, \"images total in the training set.\\n\")\n",
    "\n",
    "print('Target Distributon:')\n",
    "print('{}% normal'.format(round(len_normal_train/len_total_train * 100, 2)))\n",
    "print('{}% pneumonia'.format(round(len_pneu_train/len_total_train * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 images total in the validation set.\n",
      "There are 624 images total in the test set.\n"
     ]
    }
   ],
   "source": [
    "len_normal_val = len(os.listdir('./chest_xray/val/NORMAL'))\n",
    "len_pneu_val = len(os.listdir('./chest_xray/val/PNEUMONIA'))\n",
    "len_total_val = len_normal_val + len_pneu_val\n",
    "\n",
    "len_normal_test = len(os.listdir('./chest_xray/test/NORMAL'))\n",
    "len_pneu_test = len(os.listdir('./chest_xray/test/PNEUMONIA'))\n",
    "len_total_test = len_normal_test + len_pneu_test\n",
    "\n",
    "print(\"There are\", len_total_val, \"images total in the validation set.\")\n",
    "print(\"There are\", len_total_test, \"images total in the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 89.07% of data to train\n",
      "Using 0.27% of data to validate\n",
      "Using 10.66% of data to test\n"
     ]
    }
   ],
   "source": [
    "num_images_total = len_total_train + len_total_val + len_total_test\n",
    "print('Using {}% of data to train'.format(round(len_total_train / num_images_total *100,2)))\n",
    "print('Using {}% of data to validate'.format(round(len_total_val / num_images_total *100,2)))\n",
    "print('Using {}% of data to test'.format(round(len_total_test / num_images_total *100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like we do not have a very good split between our training and validation data -- having only 16 images / less than 1% of our data to validate with will lead to higher variance in our evaluation metrics when trying to optimize our models.  \n",
    "\n",
    "Need to move random 5% of train/pneumonia images and 5% of train/normal images into corresponding validation folder to fix this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many images to move over -- 9% of total train data.  \n",
    "# Note that this will make our imbalance in the train data WORSE -- will address this imbalance when augment more data later\n",
    "len_total_train * .1  / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of file names for train normal + train pneumonia\n",
    "\n",
    "normal_train_images = [file for file in os.listdir('./chest_xray/train/NORMAL')]\n",
    "pneu_train_images = [file for file in os.listdir('./chest_xray/train/PNEUMONIA')]\n",
    "\n",
    "# randomly choose indicies for 5% of data (both normal + pneumonia)\n",
    "normal_inds = np.random.choice(range(len_normal_train), size=250, replace=False)\n",
    "pneu_inds = np.random.choice(range(len_pneu_train), size=250, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move chosen images to validatoin folders\n",
    "#for i in normal_inds:\n",
    "#    image = normal_train_images[i]\n",
    "#    origin = './chest_xray/train/NORMAL/' + image\n",
    "#    destination = './chest_xray/val/NORMAL/' + image\n",
    "#    shutil.move(origin, destination)\n",
    "    \n",
    "#for i in pneu_inds:\n",
    "#    image = pneu_train_images[i]\n",
    "#    origin = './chest_xray/train/PNEUMONIA/' + image\n",
    "#    destination = './chest_xray/val/PNEUMONIA/' + image\n",
    "#    shutil.move(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5216 images total in the training set.\n",
      "There are 16 images total in the validation set.\n",
      "There are 624 images total in the test set.\n",
      "\n",
      "Using 89.07% of data to train\n",
      "Using 0.27% of data to validate\n",
      "Using 10.66% of data to test\n"
     ]
    }
   ],
   "source": [
    "len_normal_val = len(os.listdir('./chest_xray/val/NORMAL'))\n",
    "len_pneu_val = len(os.listdir('./chest_xray/val/PNEUMONIA'))\n",
    "len_total_val = len_normal_val + len_pneu_val\n",
    "\n",
    "len_normal_test = len(os.listdir('./chest_xray/test/NORMAL'))\n",
    "len_pneu_test = len(os.listdir('./chest_xray/test/PNEUMONIA'))\n",
    "len_total_test = len_normal_test + len_pneu_test\n",
    "\n",
    "print(\"There are\", len_total_train, \"images total in the training set.\")\n",
    "print(\"There are\", len_total_val, \"images total in the validation set.\")\n",
    "print(\"There are\", len_total_test, \"images total in the test set.\\n\")\n",
    "\n",
    "num_images_total = len_total_train + len_total_val + len_total_test\n",
    "print('Using {}% of data to train'.format(round(len_total_train / num_images_total *100,2)))\n",
    "print('Using {}% of data to validate'.format(round(len_total_val / num_images_total *100,2)))\n",
    "print('Using {}% of data to test'.format(round(len_total_test / num_images_total *100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are definately seeing some imbalance in our target.  We will need to generate some data with data augmentation to address this imbalance prior to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at some images\n",
    "\n",
    "## To do this, need to process the \n",
    "\n",
    "train_dir = 'chest_xray_images/train'\n",
    "val_dir = 'chest_xray_images/test'\n",
    "test_dir = 'chest_xray_images/val'\n",
    "\n",
    "# all images will be rescaled by 1./225\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    # Resize images down to 150x150\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "#val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "#                                                target_size=(150,150),\n",
    "#                                                batch_size=20,\n",
    "#                                                class_mode='binary')\n",
    "\n",
    "#test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "#                                                  target_size=(150,150),\n",
    "#                                                  batch_size=20,\n",
    "#                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data set for visualization\n",
    "train_images, train_labels = next(train_generator)\n",
    "# val_images, val_labels = next(val_generator)\n",
    "# test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=4, nrows=2, figsize=(15,8))\n",
    "classes = list(train_generator.class_indices.keys())\n",
    "\n",
    "for i in range(8):\n",
    "    row = i // 4 \n",
    "    col = i % 4\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    ax.imshow(train_images[i])\n",
    "    label = int(train_labels[i])\n",
    "    ax.set_title(classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration\n",
    "\n",
    "## Baseline Model\n",
    "\n",
    "- Baseline model is Dense Neural Network -- then will iterate through a CNN, then optimize that CNN (assuming does better)\n",
    "\n",
    "- Build Model (Dense model as base line -- convolutonal in further iterations\n",
    "- Evaluate with loss + accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because baseline model using is a dense NN, will need to reshape data arrays prior to modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "- CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNs take in the image itself (not reshaped) as the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "- optimize CNN (assuming better than Dense NN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Evaluation\n",
    "\n",
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
